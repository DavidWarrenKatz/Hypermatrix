{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd119ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr\n",
    "import h5py\n",
    "import scipy.io\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71712335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b15cb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros before shifting in the tensor is: 0\n",
      "The original minimum value in the tensor is: -19.931568569324174\n",
      "The new minimum value in the tensor is: 0.0\n",
      "Number of NaNs in the tensor is: 0\n",
      "Number of zeros in the tensor is: 1622306\n",
      "Number of infinities in the tensor is: 0\n",
      "The original minimum value in the zscore tensor is: -1.7320507103846263\n",
      "The new minimum value in the zscore tensor is: 0.0\n",
      "Number of NaNs in the z-scores: 0\n",
      "Number of zeros in the z-scores: 1\n",
      "Number of positive infinities in the z-scores: 0\n"
     ]
    }
   ],
   "source": [
    "# Load the RNA data from the gzip-compressed CSV file\n",
    "file_path = '/home/dwk681/workspace/GSE141252_Stoeger_et_al._2022/data/GSE141252_raw_counts.csv.gz'\n",
    "rna_data = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# Extract gene names\n",
    "genes = rna_data['gene_ensembl']\n",
    "\n",
    "# Assuming the first column is 'gene_ensembl', and the rest are samples\n",
    "sample_columns = rna_data.columns[1:]\n",
    "\n",
    "# Initialize a dictionary to hold the b_ij matrix for each tissue\n",
    "fold_change_matrices = {}\n",
    "\n",
    "# Define the age groups to compute fold changes for\n",
    "age_groups = ['09M', '12M', '18M', '24M']  # All age-groupd except for 04M, which is the baseline\n",
    "tissues = ['Adrenal', 'BAT', 'Blood', 'Brain', 'Cerebellum', 'Esophagus', 'GutEP', 'Heart', 'Kidney', 'LI', 'Liver', 'Lung', 'MuscSat', 'SI', 'Skin', 'Stomach', 'WAT']\n",
    "\n",
    "# Initialize a dictionary to hold the fold change dataframes for each tissue\n",
    "fold_changes_dfs = {}\n",
    "\n",
    "# Calculate the fold changes for each tissue and age\n",
    "for tissue in tissues:\n",
    "    # Calculate total signal for the 4-month baseline for this tissue\n",
    "    baseline_columns = [col for col in rna_data.columns if tissue in col and '04M' in col]\n",
    "    baseline_avg = rna_data[baseline_columns].mean(axis=1)\n",
    "    total_baseline_avg = baseline_avg.sum()\n",
    "    # Calculate the percentage of each entry\n",
    "    baseline_percentage = (baseline_avg / total_baseline_avg) * 10000\n",
    "    \n",
    "    # Initialize a DataFrame to store fold changes for this tissue\n",
    "    fold_changes = pd.DataFrame(index=genes, columns=age_groups)\n",
    "    \n",
    "    for age in age_groups:\n",
    "        # Calculate total signal for this age group for this tissue\n",
    "        age_columns = [col for col in rna_data.columns if tissue in col and age in col]\n",
    "        age_avg = rna_data[age_columns].mean(axis=1)\n",
    "        total_age_avg = age_avg.sum()\n",
    "        # Calculate the percentage of each entry\n",
    "        age_percentage = (age_avg / total_age_avg) * 10000\n",
    "        \n",
    "        # Calculate log2 fold change and store in the DataFrame\n",
    "        fold_changes.loc[:, age] = np.log2(  (age_percentage / (baseline_percentage + 1e-6))   + 1e-6  )  # Adding a small constant to avoid log(0)\n",
    "\n",
    "    # Store the fold change DataFrame for this tissue\n",
    "    fold_changes_dfs[tissue] = fold_changes\n",
    "\n",
    "# make the data frame into a tensor\n",
    "# The number of genes and age groups are constant, but the number of tissues varies\n",
    "num_genes = len(genes)\n",
    "num_ages = len(age_groups)\n",
    "num_tissues = len(tissues)\n",
    "\n",
    "# Initialize a 3D numpy array (tensor) with zeros\n",
    "fold_change_tensor = np.zeros((num_tissues, num_genes, num_ages))\n",
    "\n",
    "# Populate the tensor with the fold change values\n",
    "for t_idx, tissue in enumerate(tissues):\n",
    "    for a_idx, age in enumerate(age_groups):\n",
    "        # Select the fold change values for the current tissue and age group\n",
    "        fold_change_values = fold_changes_dfs[tissue][age].values\n",
    "        # Assign the values to the correct slice of the tensor\n",
    "        fold_change_tensor[t_idx, :, a_idx] = fold_change_values\n",
    "\n",
    "#print out statistics for tensor to make sure everything looks ok  \n",
    "zero_count = np.sum(fold_change_tensor == 0)  \n",
    "print(\"Number of zeros before shifting in the tensor is:\", zero_count)\n",
    "min_value = fold_change_tensor.min()\n",
    "if min_value < 0:\n",
    "    fold_change_tensor += abs(min_value)\n",
    "new_min_value = fold_change_tensor.min()    \n",
    "nan_count = np.sum(np.isnan(fold_change_tensor))    \n",
    "zero_count = np.sum(fold_change_tensor == 0)    \n",
    "inf_count = np.sum(np.isinf(fold_change_tensor))\n",
    "print(\"The original minimum value in the tensor is:\", min_value)\n",
    "print(\"The new minimum value in the tensor is:\", new_min_value)\n",
    "print(\"Number of NaNs in the tensor is:\", nan_count)\n",
    "print(\"Number of zeros in the tensor is:\", zero_count)\n",
    "print(\"Number of infinities in the tensor is:\", inf_count)    \n",
    "\n",
    "#take the zscore with respect to age and then print out statistics to make sure evyerhting looks ok\n",
    "zscored_tensor = zscore(fold_change_tensor, axis=2)\n",
    "zscored_tensor = np.nan_to_num(zscored_tensor)\n",
    "min_value = zscored_tensor.min()\n",
    "if min_value < 0:\n",
    "    zscored_tensor += abs(min_value)\n",
    "new_min_value = zscored_tensor.min()\n",
    "nan_count = np.sum(np.isnan(zscored_tensor))\n",
    "zero_count = np.sum(zscored_tensor == 0)\n",
    "inf_count = np.sum(np.isinf(zscored_tensor))\n",
    "print(\"The original minimum value in the zscore tensor is:\", min_value)\n",
    "print(\"The new minimum value in the zscore tensor is:\", new_min_value)\n",
    "print(\"Number of NaNs in the z-scores:\", nan_count)\n",
    "print(\"Number of zeros in the z-scores:\", zero_count)\n",
    "print(\"Number of positive infinities in the z-scores:\", inf_count)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc1296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b14245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tissues = ['Adrenal', 'BAT', 'Blood', 'Brain', 'Cerebellum', 'Esophagus', 'GutEP', 'Heart', 'Kidney', 'LI', 'Liver', 'Lung', 'MuscSat', 'SI', 'Skin', 'Stomach', 'WAT']\n",
    "#fold_changes_dfs['BAT']\n",
    "#zscored_tensor_non_negative.shape\n",
    "\n",
    "h5_file_path = '/home/dwk681/workspace/GSE141252_Stoeger_et_al._2022/tensor_data/RNA_tensor.h5'\n",
    "\n",
    "with h5py.File(h5_file_path, 'w') as h5_file:\n",
    "    # Create datasets for each tensor\n",
    "    h5_file.create_dataset('fold_change_tensor', data=fold_change_tensor)\n",
    "    h5_file.create_dataset('zscored_tensor', data=zscored_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MATLAB results\n",
    "file_path = '/home/dwk681/workspace/GSE141252_Stoeger_et_al._2022/fold_change_tensor_non_negative_results.mat'\n",
    "data = scipy.io.loadmat(file_path)\n",
    "\n",
    "# Extract the sol_factors\n",
    "sol_factors = data['sol_factors']\n",
    "\n",
    "# Analyze the results\n",
    "# Example: Print the shapes of the factors\n",
    "for i in range(sol_factors.shape[1]):\n",
    "    u, v, p = sol_factors[0, i]\n",
    "    print(f\"Rank {i+1}: U shape = {u.shape}, V shape = {v.shape}, P shape = {p.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7ce8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                    09M  12M  18M  24M\n",
       " gene_ensembl                          \n",
       " ENSMUSG00000000001  NaN  NaN  NaN  NaN\n",
       " ENSMUSG00000000003  NaN  NaN  NaN  NaN\n",
       " ENSMUSG00000000028  NaN  NaN  NaN  NaN\n",
       " ENSMUSG00000000031  NaN  NaN  NaN  NaN\n",
       " ENSMUSG00000000037  NaN  NaN  NaN  NaN,\n",
       " ['ENSMUSG00000000001',\n",
       "  'ENSMUSG00000000003',\n",
       "  'ENSMUSG00000000028',\n",
       "  'ENSMUSG00000000031',\n",
       "  'ENSMUSG00000000037'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Repeat the above step but first filter out all genes that are not being expressed at all\n",
    "# Initialize a dictionary to hold the expression dataframes for each tissue\n",
    "expression_dfs = {}\n",
    "\n",
    "# Calculate and store expression data for each tissue and age group\n",
    "for tissue in tissues:\n",
    "    tissue_expression = pd.DataFrame(index=genes, columns=age_groups)\n",
    "    for age in age_groups:\n",
    "        # Calculate total signal for this age group for this tissue\n",
    "        age_columns = [col for col in rna_data.columns if tissue in col and age in col]\n",
    "        age_avg = rna_data[age_columns].mean(axis=1)\n",
    "        tissue_expression[age] = age_avg\n",
    "    expression_dfs[tissue] = tissue_expression.copy()  # Use .copy() to ensure each tissue has its own DataFrame\n",
    "\n",
    "    \n",
    "# Initialize a mask with all True values\n",
    "non_zero_genes_mask = pd.Series(True, index=expression_dfs[tissues[0]].index)\n",
    "\n",
    "# Update the mask to be False for genes with zero expression in any tissue at any age\n",
    "for tissue in tissues:\n",
    "    non_zero_genes_mask &= (expression_dfs[tissue] != 0).any(axis=1)\n",
    "\n",
    "# Filter the expression dataframes\n",
    "expression_dfs_filtered = {tissue: df[non_zero_genes_mask] for tissue, df in expression_dfs.items()}\n",
    "\n",
    "# Update the genes list\n",
    "genes_filtered = non_zero_genes_mask[non_zero_genes_mask].index.tolist()\n",
    "\n",
    "# Displaying the first few rows of the filtered DataFrame for a sample tissue and the updated genes list\n",
    "(expression_dfs_filtered[tissues[0]].head(), genes_filtered[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a790db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "48becca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nfor tissue in tissues:\\n    for age in age_groups:\\n        nan_exists = fold_change_dfs[tissue][age].isna().any()\\n        print(f\"Are there NaN values in the fold change data for {tissue} at {age}? {nan_exists}\")\\n'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uncommnet if you want to make sure there are no NANs in the data frame\n",
    "''' \n",
    "for tissue in tissues:\n",
    "    for age in age_groups:\n",
    "        nan_exists = fold_change_dfs[tissue][age].isna().any()\n",
    "        print(f\"Are there NaN values in the fold change data for {tissue} at {age}? {nan_exists}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0e4f43b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         0         1         2         3         4    \\\n",
      "gene_ensembl                                                           \n",
      "ENSMUSG00000000001  0.548814  0.715189  0.602763  0.544883  0.423655   \n",
      "ENSMUSG00000000003  0.311796  0.696343  0.377752  0.179604  0.024679   \n",
      "ENSMUSG00000000028  0.401260  0.929291  0.099615  0.945302  0.869489   \n",
      "ENSMUSG00000000031  0.174658  0.327988  0.680349  0.063208  0.607249   \n",
      "ENSMUSG00000000037  0.039993  0.639705  0.408303  0.377407  0.809365   \n",
      "\n",
      "                         5         6         7         8         9    ...  \\\n",
      "gene_ensembl                                                          ...   \n",
      "ENSMUSG00000000001  0.645894  0.437587  0.891773  0.963663  0.383442  ...   \n",
      "ENSMUSG00000000003  0.067250  0.679393  0.453697  0.536579  0.896671  ...   \n",
      "ENSMUSG00000000028  0.454162  0.326701  0.232744  0.614465  0.033075  ...   \n",
      "ENSMUSG00000000031  0.477647  0.284000  0.238413  0.514513  0.367928  ...   \n",
      "ENSMUSG00000000037  0.709035  0.954334  0.351936  0.897543  0.769967  ...   \n",
      "\n",
      "                         190       191       192       193       194  \\\n",
      "gene_ensembl                                                           \n",
      "ENSMUSG00000000001  0.398221  0.209844  0.186193  0.944372  0.739551   \n",
      "ENSMUSG00000000003  0.062713  0.424032  0.258684  0.849038  0.033305   \n",
      "ENSMUSG00000000028  0.739884  0.898062  0.672582  0.528940  0.304446   \n",
      "ENSMUSG00000000031  0.568218  0.246557  0.596433  0.117526  0.975884   \n",
      "ENSMUSG00000000037  0.012171  0.322830  0.229567  0.506863  0.736853   \n",
      "\n",
      "                         195       196       197       198       199  \n",
      "gene_ensembl                                                          \n",
      "ENSMUSG00000000001  0.490459  0.227415  0.254356  0.058029  0.434417  \n",
      "ENSMUSG00000000003  0.958983  0.355369  0.356707  0.016329  0.185232  \n",
      "ENSMUSG00000000028  0.997962  0.362189  0.470649  0.378245  0.979527  \n",
      "ENSMUSG00000000031  0.932561  0.391797  0.242179  0.250398  0.483394  \n",
      "ENSMUSG00000000037  0.097676  0.514922  0.938412  0.228647  0.677141  \n",
      "\n",
      "[5 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you know the number of genes. Replace this with the actual number.\n",
    "num_genes = len(genes)  # Example number, replace with the actual number of genes\n",
    "\n",
    "# Define the number of features you want to simulate\n",
    "num_features = 200  # Example number of features\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "features_matrix = pd.DataFrame(np.random.rand(num_genes, num_features), index=genes)\n",
    "\n",
    "# Display the first few rows of the simulated features_matrix\n",
    "print(features_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f4538d81",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Create and train the gradient-boosting model\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m GradientBoostingRegressor(random_state\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Store feature importances and calculate median rank\u001b[39;00m\n\u001b[1;32m     29\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_importances_\n",
      "File \u001b[0;32m~/.conda/envs/scRNAseq/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/scRNAseq/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:532\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/scRNAseq/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:610\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    603\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[1;32m    604\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    605\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    606\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    607\u001b[0m         )\n\u001b[1;32m    609\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 610\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/.conda/envs/scRNAseq/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    242\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    244\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 245\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    248\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[1;32m    249\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[1;32m    250\u001b[0m     X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    257\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[1;32m    258\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/scRNAseq/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/scRNAseq/lib/python3.8/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/scRNAseq/lib/python3.8/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store models, median ranks, and evaluation metrics\n",
    "models_dict = {}\n",
    "median_ranks_dict = {}\n",
    "evaluation_dict = {}\n",
    "\n",
    "for tissue in tissues:\n",
    "    for age in age_groups:\n",
    "        num_models = 10\n",
    "        tissue_age_models = []\n",
    "        median_ranks = []\n",
    "        correlations = []  # Initialize correlations list\n",
    "\n",
    "        for i in range(num_models):\n",
    "            # Ensure that the target vector (fold change values) aligns with the features_matrix\n",
    "            y = fold_change_dfs[tissue][age].reindex(features_matrix.index)\n",
    "\n",
    "            # Split the data into train and test sets\n",
    "            X_train, X_test, y_train, y_test = train_test_split(features_matrix, y, test_size=0.1, random_state=i)\n",
    "\n",
    "            # Create and train the gradient-boosting model\n",
    "            model = GradientBoostingRegressor(random_state=i)\n",
    "            model.fit(X_train.dropna(), y_train.dropna())  # Ensure no NaN values\n",
    "\n",
    "            # Store the model\n",
    "            tissue_age_models.append(model)\n",
    "\n",
    "            # Calculate and store feature importances and median rank\n",
    "            feature_importances = model.feature_importances_\n",
    "            ranked_features = np.argsort(feature_importances)[::-1]  # Rank features by importance\n",
    "            median_rank = np.median(ranked_features)\n",
    "            median_ranks.append(median_rank)\n",
    "\n",
    "            # Evaluate the model on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "            correlation, _ = spearmanr(y_test, y_pred)\n",
    "            correlations.append(correlation)\n",
    "\n",
    "        # Store the models, median ranks, and median correlations for this tissue-age group\n",
    "        models_dict[(tissue, age)] = tissue_age_models\n",
    "        median_ranks_dict[(tissue, age)] = np.median(median_ranks)\n",
    "        evaluation_dict[(tissue, age)] = np.median(correlations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "63f05f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gene_0</th>\n",
       "      <td>0.548814</td>\n",
       "      <td>0.715189</td>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.423655</td>\n",
       "      <td>0.645894</td>\n",
       "      <td>0.437587</td>\n",
       "      <td>0.891773</td>\n",
       "      <td>0.963663</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398221</td>\n",
       "      <td>0.209844</td>\n",
       "      <td>0.186193</td>\n",
       "      <td>0.944372</td>\n",
       "      <td>0.739551</td>\n",
       "      <td>0.490459</td>\n",
       "      <td>0.227415</td>\n",
       "      <td>0.254356</td>\n",
       "      <td>0.058029</td>\n",
       "      <td>0.434417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene_1</th>\n",
       "      <td>0.311796</td>\n",
       "      <td>0.696343</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>0.179604</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.067250</td>\n",
       "      <td>0.679393</td>\n",
       "      <td>0.453697</td>\n",
       "      <td>0.536579</td>\n",
       "      <td>0.896671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062713</td>\n",
       "      <td>0.424032</td>\n",
       "      <td>0.258684</td>\n",
       "      <td>0.849038</td>\n",
       "      <td>0.033305</td>\n",
       "      <td>0.958983</td>\n",
       "      <td>0.355369</td>\n",
       "      <td>0.356707</td>\n",
       "      <td>0.016329</td>\n",
       "      <td>0.185232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene_2</th>\n",
       "      <td>0.401260</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>0.099615</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>0.869489</td>\n",
       "      <td>0.454162</td>\n",
       "      <td>0.326701</td>\n",
       "      <td>0.232744</td>\n",
       "      <td>0.614465</td>\n",
       "      <td>0.033075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.898062</td>\n",
       "      <td>0.672582</td>\n",
       "      <td>0.528940</td>\n",
       "      <td>0.304446</td>\n",
       "      <td>0.997962</td>\n",
       "      <td>0.362189</td>\n",
       "      <td>0.470649</td>\n",
       "      <td>0.378245</td>\n",
       "      <td>0.979527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene_3</th>\n",
       "      <td>0.174658</td>\n",
       "      <td>0.327988</td>\n",
       "      <td>0.680349</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.607249</td>\n",
       "      <td>0.477647</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.238413</td>\n",
       "      <td>0.514513</td>\n",
       "      <td>0.367928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568218</td>\n",
       "      <td>0.246557</td>\n",
       "      <td>0.596433</td>\n",
       "      <td>0.117526</td>\n",
       "      <td>0.975884</td>\n",
       "      <td>0.932561</td>\n",
       "      <td>0.391797</td>\n",
       "      <td>0.242179</td>\n",
       "      <td>0.250398</td>\n",
       "      <td>0.483394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene_4</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.639705</td>\n",
       "      <td>0.408303</td>\n",
       "      <td>0.377407</td>\n",
       "      <td>0.809365</td>\n",
       "      <td>0.709035</td>\n",
       "      <td>0.954334</td>\n",
       "      <td>0.351936</td>\n",
       "      <td>0.897543</td>\n",
       "      <td>0.769967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>0.322830</td>\n",
       "      <td>0.229567</td>\n",
       "      <td>0.506863</td>\n",
       "      <td>0.736853</td>\n",
       "      <td>0.097676</td>\n",
       "      <td>0.514922</td>\n",
       "      <td>0.938412</td>\n",
       "      <td>0.228647</td>\n",
       "      <td>0.677141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene_43425</th>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.313539</td>\n",
       "      <td>0.058766</td>\n",
       "      <td>0.499187</td>\n",
       "      <td>0.808221</td>\n",
       "      <td>0.138732</td>\n",
       "      <td>0.301711</td>\n",
       "      <td>0.577402</td>\n",
       "      <td>0.157363</td>\n",
       "      <td>0.523020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211563</td>\n",
       "      <td>0.824925</td>\n",
       "      <td>0.388509</td>\n",
       "      <td>0.205365</td>\n",
       "      <td>0.611693</td>\n",
       "      <td>0.375046</td>\n",
       "      <td>0.183240</td>\n",
       "      <td>0.967246</td>\n",
       "      <td>0.087562</td>\n",
       "      <td>0.069967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene_43426</th>\n",
       "      <td>0.543741</td>\n",
       "      <td>0.951535</td>\n",
       "      <td>0.600908</td>\n",
       "      <td>0.910568</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.098114</td>\n",
       "      <td>0.383854</td>\n",
       "      <td>0.286133</td>\n",
       "      <td>0.111796</td>\n",
       "      <td>0.869804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.969875</td>\n",
       "      <td>0.148484</td>\n",
       "      <td>0.963825</td>\n",
       "      <td>0.452016</td>\n",
       "      <td>0.216094</td>\n",
       "      <td>0.799398</td>\n",
       "      <td>0.056839</td>\n",
       "      <td>0.895741</td>\n",
       "      <td>0.657543</td>\n",
       "      <td>0.814228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene_43427</th>\n",
       "      <td>0.638730</td>\n",
       "      <td>0.528217</td>\n",
       "      <td>0.284441</td>\n",
       "      <td>0.994471</td>\n",
       "      <td>0.296285</td>\n",
       "      <td>0.881466</td>\n",
       "      <td>0.497050</td>\n",
       "      <td>0.738617</td>\n",
       "      <td>0.565598</td>\n",
       "      <td>0.956137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132096</td>\n",
       "      <td>0.914367</td>\n",
       "      <td>0.025866</td>\n",
       "      <td>0.659436</td>\n",
       "      <td>0.353251</td>\n",
       "      <td>0.868699</td>\n",
       "      <td>0.194066</td>\n",
       "      <td>0.458481</td>\n",
       "      <td>0.392778</td>\n",
       "      <td>0.263316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene_43428</th>\n",
       "      <td>0.087231</td>\n",
       "      <td>0.090555</td>\n",
       "      <td>0.344656</td>\n",
       "      <td>0.593301</td>\n",
       "      <td>0.958200</td>\n",
       "      <td>0.172662</td>\n",
       "      <td>0.580123</td>\n",
       "      <td>0.358753</td>\n",
       "      <td>0.348730</td>\n",
       "      <td>0.880162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072910</td>\n",
       "      <td>0.099553</td>\n",
       "      <td>0.707749</td>\n",
       "      <td>0.686611</td>\n",
       "      <td>0.676574</td>\n",
       "      <td>0.645875</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.275626</td>\n",
       "      <td>0.800352</td>\n",
       "      <td>0.415574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gene_43429</th>\n",
       "      <td>0.020439</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.681310</td>\n",
       "      <td>0.059247</td>\n",
       "      <td>0.638324</td>\n",
       "      <td>0.281876</td>\n",
       "      <td>0.797858</td>\n",
       "      <td>0.524217</td>\n",
       "      <td>0.222334</td>\n",
       "      <td>0.115316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589998</td>\n",
       "      <td>0.962062</td>\n",
       "      <td>0.579665</td>\n",
       "      <td>0.884588</td>\n",
       "      <td>0.127729</td>\n",
       "      <td>0.411272</td>\n",
       "      <td>0.727304</td>\n",
       "      <td>0.348744</td>\n",
       "      <td>0.684728</td>\n",
       "      <td>0.000808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43430 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5    \\\n",
       "Gene_0      0.548814  0.715189  0.602763  0.544883  0.423655  0.645894   \n",
       "Gene_1      0.311796  0.696343  0.377752  0.179604  0.024679  0.067250   \n",
       "Gene_2      0.401260  0.929291  0.099615  0.945302  0.869489  0.454162   \n",
       "Gene_3      0.174658  0.327988  0.680349  0.063208  0.607249  0.477647   \n",
       "Gene_4      0.039993  0.639705  0.408303  0.377407  0.809365  0.709035   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "Gene_43425  0.002580  0.313539  0.058766  0.499187  0.808221  0.138732   \n",
       "Gene_43426  0.543741  0.951535  0.600908  0.910568  0.998656  0.098114   \n",
       "Gene_43427  0.638730  0.528217  0.284441  0.994471  0.296285  0.881466   \n",
       "Gene_43428  0.087231  0.090555  0.344656  0.593301  0.958200  0.172662   \n",
       "Gene_43429  0.020439  0.880435  0.681310  0.059247  0.638324  0.281876   \n",
       "\n",
       "                 6         7         8         9    ...       190       191  \\\n",
       "Gene_0      0.437587  0.891773  0.963663  0.383442  ...  0.398221  0.209844   \n",
       "Gene_1      0.679393  0.453697  0.536579  0.896671  ...  0.062713  0.424032   \n",
       "Gene_2      0.326701  0.232744  0.614465  0.033075  ...  0.739884  0.898062   \n",
       "Gene_3      0.284000  0.238413  0.514513  0.367928  ...  0.568218  0.246557   \n",
       "Gene_4      0.954334  0.351936  0.897543  0.769967  ...  0.012171  0.322830   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "Gene_43425  0.301711  0.577402  0.157363  0.523020  ...  0.211563  0.824925   \n",
       "Gene_43426  0.383854  0.286133  0.111796  0.869804  ...  0.969875  0.148484   \n",
       "Gene_43427  0.497050  0.738617  0.565598  0.956137  ...  0.132096  0.914367   \n",
       "Gene_43428  0.580123  0.358753  0.348730  0.880162  ...  0.072910  0.099553   \n",
       "Gene_43429  0.797858  0.524217  0.222334  0.115316  ...  0.589998  0.962062   \n",
       "\n",
       "                 192       193       194       195       196       197  \\\n",
       "Gene_0      0.186193  0.944372  0.739551  0.490459  0.227415  0.254356   \n",
       "Gene_1      0.258684  0.849038  0.033305  0.958983  0.355369  0.356707   \n",
       "Gene_2      0.672582  0.528940  0.304446  0.997962  0.362189  0.470649   \n",
       "Gene_3      0.596433  0.117526  0.975884  0.932561  0.391797  0.242179   \n",
       "Gene_4      0.229567  0.506863  0.736853  0.097676  0.514922  0.938412   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "Gene_43425  0.388509  0.205365  0.611693  0.375046  0.183240  0.967246   \n",
       "Gene_43426  0.963825  0.452016  0.216094  0.799398  0.056839  0.895741   \n",
       "Gene_43427  0.025866  0.659436  0.353251  0.868699  0.194066  0.458481   \n",
       "Gene_43428  0.707749  0.686611  0.676574  0.645875  0.174200  0.275626   \n",
       "Gene_43429  0.579665  0.884588  0.127729  0.411272  0.727304  0.348744   \n",
       "\n",
       "                 198       199  \n",
       "Gene_0      0.058029  0.434417  \n",
       "Gene_1      0.016329  0.185232  \n",
       "Gene_2      0.378245  0.979527  \n",
       "Gene_3      0.250398  0.483394  \n",
       "Gene_4      0.228647  0.677141  \n",
       "...              ...       ...  \n",
       "Gene_43425  0.087562  0.069967  \n",
       "Gene_43426  0.657543  0.814228  \n",
       "Gene_43427  0.392778  0.263316  \n",
       "Gene_43428  0.800352  0.415574  \n",
       "Gene_43429  0.684728  0.000808  \n",
       "\n",
       "[43430 rows x 200 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cc9bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9db06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302ed6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db75cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76675578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684519df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ab85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91931aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_ensembl</th>\n",
       "      <th>ENSMUSG00000071633</th>\n",
       "      <th>ENSMUSG00000039234</th>\n",
       "      <th>ENSMUSG00000076710</th>\n",
       "      <th>ENSMUSG00000095554</th>\n",
       "      <th>ENSMUSG00000071303</th>\n",
       "      <th>ENSMUSG00000050505</th>\n",
       "      <th>ENSMUSG00000026393</th>\n",
       "      <th>ENSMUSG00000084331</th>\n",
       "      <th>ENSMUSG00000101847</th>\n",
       "      <th>ENSMUSG00000011958</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSMUSG00000032623</th>\n",
       "      <th>ENSMUSG00000100088</th>\n",
       "      <th>ENSMUSG00000085197</th>\n",
       "      <th>ENSMUSG00000041700</th>\n",
       "      <th>ENSMUSG00000102394</th>\n",
       "      <th>ENSMUSG00000094822</th>\n",
       "      <th>ENSMUSG00000038537</th>\n",
       "      <th>ENSMUSG00000032392</th>\n",
       "      <th>ENSMUSG00000022032</th>\n",
       "      <th>ENSMUSG00000034164</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M01_Adrenal_24M_F0_1</th>\n",
       "      <td>-6.274507</td>\n",
       "      <td>-0.356970</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712374</td>\n",
       "      <td>-4.081074</td>\n",
       "      <td>0.159494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830466</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>-3.063762</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>1.497945</td>\n",
       "      <td>0.143703</td>\n",
       "      <td>-2.422385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M01_BAT_24M_F0_1</th>\n",
       "      <td>-6.274507</td>\n",
       "      <td>-3.007735</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712374</td>\n",
       "      <td>-4.081074</td>\n",
       "      <td>0.168043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>-3.063762</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>-0.411081</td>\n",
       "      <td>-1.032795</td>\n",
       "      <td>-1.574388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M01_Blood_24M_F0_1</th>\n",
       "      <td>-6.274507</td>\n",
       "      <td>-7.651591</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712374</td>\n",
       "      <td>-4.081074</td>\n",
       "      <td>-6.913041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.532939</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>-3.063762</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>-5.902934</td>\n",
       "      <td>-7.222619</td>\n",
       "      <td>-2.422385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M01_Brain_24M_F0_1</th>\n",
       "      <td>-6.274507</td>\n",
       "      <td>-7.651591</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712374</td>\n",
       "      <td>-4.081074</td>\n",
       "      <td>-9.234969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.702864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>-3.063762</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>-5.902934</td>\n",
       "      <td>-7.222619</td>\n",
       "      <td>-4.744313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M01_Esophagus_24M_F0_1</th>\n",
       "      <td>-6.274507</td>\n",
       "      <td>-0.394203</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712374</td>\n",
       "      <td>-4.081074</td>\n",
       "      <td>0.258886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556880</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>2.428091</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>-0.545382</td>\n",
       "      <td>1.613431</td>\n",
       "      <td>-1.574388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M36_Lung_24M_F150_2</th>\n",
       "      <td>-6.274507</td>\n",
       "      <td>-1.112432</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712374</td>\n",
       "      <td>-4.081074</td>\n",
       "      <td>-0.838364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.272411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>-3.063762</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>-2.733009</td>\n",
       "      <td>-2.830302</td>\n",
       "      <td>0.300081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M37_Lung_24M_F150_3</th>\n",
       "      <td>-6.274507</td>\n",
       "      <td>-0.553559</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712374</td>\n",
       "      <td>-4.081074</td>\n",
       "      <td>-1.100543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.191111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>-3.063762</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>-2.202494</td>\n",
       "      <td>-2.578763</td>\n",
       "      <td>-0.656850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M50_Lung_24M_F150_4</th>\n",
       "      <td>-6.274507</td>\n",
       "      <td>-0.596308</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712374</td>\n",
       "      <td>-1.759146</td>\n",
       "      <td>-0.691937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288658</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>-3.063762</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>-2.202494</td>\n",
       "      <td>-1.865067</td>\n",
       "      <td>-0.351995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M51_Lung_24M_F150_5</th>\n",
       "      <td>-6.274507</td>\n",
       "      <td>-0.937345</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712374</td>\n",
       "      <td>-4.081074</td>\n",
       "      <td>-1.142212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.099237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>-3.063762</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>-3.581006</td>\n",
       "      <td>-2.013166</td>\n",
       "      <td>-0.100457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M52_Lung_24M_F150_6</th>\n",
       "      <td>-6.274507</td>\n",
       "      <td>0.187613</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.712374</td>\n",
       "      <td>-4.081074</td>\n",
       "      <td>-0.982304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315139</td>\n",
       "      <td>-3.063762</td>\n",
       "      <td>-0.026842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.399717</td>\n",
       "      <td>-2.202494</td>\n",
       "      <td>-2.364638</td>\n",
       "      <td>-1.574388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 39086 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_ensembl            ENSMUSG00000071633  ENSMUSG00000039234  \\\n",
       "M01_Adrenal_24M_F0_1             -6.274507           -0.356970   \n",
       "M01_BAT_24M_F0_1                 -6.274507           -3.007735   \n",
       "M01_Blood_24M_F0_1               -6.274507           -7.651591   \n",
       "M01_Brain_24M_F0_1               -6.274507           -7.651591   \n",
       "M01_Esophagus_24M_F0_1           -6.274507           -0.394203   \n",
       "...                                    ...                 ...   \n",
       "M36_Lung_24M_F150_2              -6.274507           -1.112432   \n",
       "M37_Lung_24M_F150_3              -6.274507           -0.553559   \n",
       "M50_Lung_24M_F150_4              -6.274507           -0.596308   \n",
       "M51_Lung_24M_F150_5              -6.274507           -0.937345   \n",
       "M52_Lung_24M_F150_6              -6.274507            0.187613   \n",
       "\n",
       "gene_ensembl            ENSMUSG00000076710  ENSMUSG00000095554  \\\n",
       "M01_Adrenal_24M_F0_1             -0.026842                 0.0   \n",
       "M01_BAT_24M_F0_1                 -0.026842                 0.0   \n",
       "M01_Blood_24M_F0_1               -0.026842                 0.0   \n",
       "M01_Brain_24M_F0_1               -0.026842                 0.0   \n",
       "M01_Esophagus_24M_F0_1           -0.026842                 0.0   \n",
       "...                                    ...                 ...   \n",
       "M36_Lung_24M_F150_2              -0.026842                 0.0   \n",
       "M37_Lung_24M_F150_3              -0.026842                 0.0   \n",
       "M50_Lung_24M_F150_4              -0.026842                 0.0   \n",
       "M51_Lung_24M_F150_5              -0.026842                 0.0   \n",
       "M52_Lung_24M_F150_6              -0.026842                 0.0   \n",
       "\n",
       "gene_ensembl            ENSMUSG00000071303  ENSMUSG00000050505  \\\n",
       "M01_Adrenal_24M_F0_1             -0.712374           -4.081074   \n",
       "M01_BAT_24M_F0_1                 -0.712374           -4.081074   \n",
       "M01_Blood_24M_F0_1               -0.712374           -4.081074   \n",
       "M01_Brain_24M_F0_1               -0.712374           -4.081074   \n",
       "M01_Esophagus_24M_F0_1           -0.712374           -4.081074   \n",
       "...                                    ...                 ...   \n",
       "M36_Lung_24M_F150_2              -0.712374           -4.081074   \n",
       "M37_Lung_24M_F150_3              -0.712374           -4.081074   \n",
       "M50_Lung_24M_F150_4              -0.712374           -1.759146   \n",
       "M51_Lung_24M_F150_5              -0.712374           -4.081074   \n",
       "M52_Lung_24M_F150_6              -0.712374           -4.081074   \n",
       "\n",
       "gene_ensembl            ENSMUSG00000026393  ENSMUSG00000084331  \\\n",
       "M01_Adrenal_24M_F0_1              0.159494                 0.0   \n",
       "M01_BAT_24M_F0_1                  0.168043                 0.0   \n",
       "M01_Blood_24M_F0_1               -6.913041                 0.0   \n",
       "M01_Brain_24M_F0_1               -9.234969                 0.0   \n",
       "M01_Esophagus_24M_F0_1            0.258886                 0.0   \n",
       "...                                    ...                 ...   \n",
       "M36_Lung_24M_F150_2              -0.838364                 0.0   \n",
       "M37_Lung_24M_F150_3              -1.100543                 0.0   \n",
       "M50_Lung_24M_F150_4              -0.691937                 0.0   \n",
       "M51_Lung_24M_F150_5              -1.142212                 0.0   \n",
       "M52_Lung_24M_F150_6              -0.982304                 0.0   \n",
       "\n",
       "gene_ensembl            ENSMUSG00000101847  ENSMUSG00000011958  ...  \\\n",
       "M01_Adrenal_24M_F0_1                   0.0            0.830466  ...   \n",
       "M01_BAT_24M_F0_1                       0.0            0.133187  ...   \n",
       "M01_Blood_24M_F0_1                     0.0           -5.532939  ...   \n",
       "M01_Brain_24M_F0_1                     0.0           -8.702864  ...   \n",
       "M01_Esophagus_24M_F0_1                 0.0            0.556880  ...   \n",
       "...                                    ...                 ...  ...   \n",
       "M36_Lung_24M_F150_2                    0.0           -0.272411  ...   \n",
       "M37_Lung_24M_F150_3                    0.0           -0.191111  ...   \n",
       "M50_Lung_24M_F150_4                    0.0            0.288658  ...   \n",
       "M51_Lung_24M_F150_5                    0.0           -0.099237  ...   \n",
       "M52_Lung_24M_F150_6                    0.0            0.081771  ...   \n",
       "\n",
       "gene_ensembl            ENSMUSG00000032623  ENSMUSG00000100088  \\\n",
       "M01_Adrenal_24M_F0_1             -0.399717                 0.0   \n",
       "M01_BAT_24M_F0_1                 -0.399717                 0.0   \n",
       "M01_Blood_24M_F0_1               -0.399717                 0.0   \n",
       "M01_Brain_24M_F0_1               -0.399717                 0.0   \n",
       "M01_Esophagus_24M_F0_1           -0.399717                 0.0   \n",
       "...                                    ...                 ...   \n",
       "M36_Lung_24M_F150_2              -0.399717                 0.0   \n",
       "M37_Lung_24M_F150_3              -0.399717                 0.0   \n",
       "M50_Lung_24M_F150_4              -0.399717                 0.0   \n",
       "M51_Lung_24M_F150_5              -0.399717                 0.0   \n",
       "M52_Lung_24M_F150_6              -0.399717                 0.0   \n",
       "\n",
       "gene_ensembl            ENSMUSG00000085197  ENSMUSG00000041700  \\\n",
       "M01_Adrenal_24M_F0_1             -0.315139           -3.063762   \n",
       "M01_BAT_24M_F0_1                 -0.315139           -3.063762   \n",
       "M01_Blood_24M_F0_1               -0.315139           -3.063762   \n",
       "M01_Brain_24M_F0_1               -0.315139           -3.063762   \n",
       "M01_Esophagus_24M_F0_1           -0.315139            2.428091   \n",
       "...                                    ...                 ...   \n",
       "M36_Lung_24M_F150_2              -0.315139           -3.063762   \n",
       "M37_Lung_24M_F150_3              -0.315139           -3.063762   \n",
       "M50_Lung_24M_F150_4              -0.315139           -3.063762   \n",
       "M51_Lung_24M_F150_5              -0.315139           -3.063762   \n",
       "M52_Lung_24M_F150_6              -0.315139           -3.063762   \n",
       "\n",
       "gene_ensembl            ENSMUSG00000102394  ENSMUSG00000094822  \\\n",
       "M01_Adrenal_24M_F0_1             -0.026842                 0.0   \n",
       "M01_BAT_24M_F0_1                 -0.026842                 0.0   \n",
       "M01_Blood_24M_F0_1               -0.026842                 0.0   \n",
       "M01_Brain_24M_F0_1               -0.026842                 0.0   \n",
       "M01_Esophagus_24M_F0_1           -0.026842                 0.0   \n",
       "...                                    ...                 ...   \n",
       "M36_Lung_24M_F150_2              -0.026842                 0.0   \n",
       "M37_Lung_24M_F150_3              -0.026842                 0.0   \n",
       "M50_Lung_24M_F150_4              -0.026842                 0.0   \n",
       "M51_Lung_24M_F150_5              -0.026842                 0.0   \n",
       "M52_Lung_24M_F150_6              -0.026842                 0.0   \n",
       "\n",
       "gene_ensembl            ENSMUSG00000038537  ENSMUSG00000032392  \\\n",
       "M01_Adrenal_24M_F0_1             -0.399717            1.497945   \n",
       "M01_BAT_24M_F0_1                 -0.399717           -0.411081   \n",
       "M01_Blood_24M_F0_1               -0.399717           -5.902934   \n",
       "M01_Brain_24M_F0_1               -0.399717           -5.902934   \n",
       "M01_Esophagus_24M_F0_1           -0.399717           -0.545382   \n",
       "...                                    ...                 ...   \n",
       "M36_Lung_24M_F150_2              -0.399717           -2.733009   \n",
       "M37_Lung_24M_F150_3              -0.399717           -2.202494   \n",
       "M50_Lung_24M_F150_4              -0.399717           -2.202494   \n",
       "M51_Lung_24M_F150_5              -0.399717           -3.581006   \n",
       "M52_Lung_24M_F150_6              -0.399717           -2.202494   \n",
       "\n",
       "gene_ensembl            ENSMUSG00000022032  ENSMUSG00000034164  \n",
       "M01_Adrenal_24M_F0_1              0.143703           -2.422385  \n",
       "M01_BAT_24M_F0_1                 -1.032795           -1.574388  \n",
       "M01_Blood_24M_F0_1               -7.222619           -2.422385  \n",
       "M01_Brain_24M_F0_1               -7.222619           -4.744313  \n",
       "M01_Esophagus_24M_F0_1            1.613431           -1.574388  \n",
       "...                                    ...                 ...  \n",
       "M36_Lung_24M_F150_2              -2.830302            0.300081  \n",
       "M37_Lung_24M_F150_3              -2.578763           -0.656850  \n",
       "M50_Lung_24M_F150_4              -1.865067           -0.351995  \n",
       "M51_Lung_24M_F150_5              -2.013166           -0.100457  \n",
       "M52_Lung_24M_F150_6              -2.364638           -1.574388  \n",
       "\n",
       "[106 rows x 39086 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Load the RNA data from the gzip-compressed CSV file\n",
    "file_path = '/home/dwk681/workspace/GSE141252_Stoeger_et_al._2022/GSE141252_raw_counts.csv.gz'\n",
    "rna_data = pd.read_csv(file_path, compression='gzip')\n",
    "\n",
    "# Extract gene names\n",
    "genes = rna_data['gene_ensembl']\n",
    "\n",
    "# Assuming the first column is 'gene_ensembl', and the rest are samples\n",
    "sample_columns = rna_data.columns[1:]\n",
    "\n",
    "# Calculate log2-transformed fold changes for each sample relative to 4-month-old mice\n",
    "# Assuming columns are named in the form 'Tissue_Age_Sample', e.g., 'Adrenal_24M_F0_1'\n",
    "fold_change_dict = {}\n",
    "for column in sample_columns:\n",
    "    _, tissue, age, _, _ = column.split('_')\n",
    "    if age != '4M':  # Skip the 4-month-old baseline\n",
    "        # Find the corresponding 4-month-old baseline columns for the same tissue\n",
    "        baseline_columns = [col for col in sample_columns if tissue in col and '4M' in col]\n",
    "        baseline_expression = rna_data[baseline_columns].mean(axis=1) + 1  # Add 1 to avoid log(0)\n",
    "        fold_change = np.log2((rna_data[column] + 1) / baseline_expression)  # Log2 fold change\n",
    "        fold_change_dict[column] = fold_change\n",
    "\n",
    "# Convert the fold change dictionary to a DataFrame\n",
    "fold_change_df = pd.DataFrame(fold_change_dict)\n",
    "\n",
    "\n",
    "# Once we have all median ranks, we can reshape the DataFrame to match the desired output\n",
    "# The final DataFrame should have tissues as rows and age groups as columns\n",
    "# This code will need to be adjusted based on the actual data and desired output format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414762d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e260c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: nan\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Number of samples and features in the synthetic dataset\n",
    "n_samples = 10\n",
    "n_features = 2236\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(n_samples, n_features)  # Feature matrix\n",
    "y = np.random.rand(n_samples)  # Target vector\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Initialize and train the Gradient Boosting Regressor\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "\n",
    "# Create a pandas Series for easier plotting\n",
    "feature_importance_series = pd.Series(feature_importance, index=range(n_features))\n",
    "\n",
    "# Sort the features by importance\n",
    "sorted_feature_importance = feature_importance_series.sort_values(ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sorted_feature_importance[:20].plot(kind='bar')  # Plotting top 20 features for visibility\n",
    "plt.title('Top 20 Feature Importances in Gradient Boosting Model')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Spearman correlation\n",
    "spearman_corr, _ = spearmanr(y_test, y_pred)\n",
    "print(f\"Spearman Correlation: {spearman_corr}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b272a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "       0.00000000e+00, 3.08331492e-07, 0.00000000e+00])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4462110",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_partial_dependence' from 'sklearn.inspection' (/home/dwk681/.conda/envs/scRNAseq/lib/python3.8/site-packages/sklearn/inspection/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_partial_dependence\n\u001b[1;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m      4\u001b[0m plot_partial_dependence(model, X_train, features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], ax\u001b[38;5;241m=\u001b[39max) \u001b[38;5;66;03m# Replace 0, 1, 2 with indices of features of interest\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_partial_dependence' from 'sklearn.inspection' (/home/dwk681/.conda/envs/scRNAseq/lib/python3.8/site-packages/sklearn/inspection/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import plot_partial_dependence\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "plot_partial_dependence(model, X_train, features=[0, 1, 2], ax=ax) # Replace 0, 1, 2 with indices of features of interest\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1021aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example of how to create a combined dataset\n",
    "combined_features = []\n",
    "combined_targets = []\n",
    "combined_tissue_age_labels = []\n",
    "\n",
    "for tissue in tissues:\n",
    "    for age in age_groups:\n",
    "        # Extract features and target for each tissue-age pair\n",
    "        features = features_matrix  # Assume features_matrix is the same for all\n",
    "        target = fold_change_dfs[tissue][age]\n",
    "\n",
    "        # Create tissue-age labels (one-hot encoded or similar)\n",
    "        tissue_age_label = f\"{tissue}_{age}\"  # Example label format\n",
    "\n",
    "        combined_features.append(features)\n",
    "        combined_targets.append(target)\n",
    "        combined_tissue_age_labels.extend([tissue_age_label] * len(target))\n",
    "\n",
    "# Convert to DataFrame or suitable format for training\n",
    "combined_features_df = pd.concat(combined_features)\n",
    "combined_targets_series = pd.concat(combined_targets)\n",
    "combined_labels_series = pd.Series(combined_tissue_age_labels)\n",
    "\n",
    "# One-hot encode the tissue-age labels\n",
    "encoder = OneHotEncoder()\n",
    "encoded_labels = encoder.fit_transform(combined_labels_series.values.reshape(-1, 1)).toarray()\n",
    "\n",
    "# Use the appropriate method to get feature names based on scikit-learn version\n",
    "try:\n",
    "    # For scikit-learn version 0.22 and later\n",
    "    encoded_labels_columns = encoder.get_feature_names_out()\n",
    "except AttributeError:\n",
    "    # For scikit-learn versions before 0.22\n",
    "    encoded_labels_columns = encoder.get_feature_names()\n",
    "\n",
    "# Add encoded labels to the features DataFrame\n",
    "encoded_labels_df = pd.DataFrame(encoded_labels, columns=encoded_labels_columns)\n",
    "combined_features_df = pd.concat([combined_features_df.reset_index(drop=True), encoded_labels_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f6f929f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_Skin_18M</th>\n",
       "      <th>x0_Skin_24M</th>\n",
       "      <th>x0_Stomach_09M</th>\n",
       "      <th>x0_Stomach_12M</th>\n",
       "      <th>x0_Stomach_18M</th>\n",
       "      <th>x0_Stomach_24M</th>\n",
       "      <th>x0_WAT_09M</th>\n",
       "      <th>x0_WAT_12M</th>\n",
       "      <th>x0_WAT_18M</th>\n",
       "      <th>x0_WAT_24M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.548814</td>\n",
       "      <td>0.715189</td>\n",
       "      <td>0.602763</td>\n",
       "      <td>0.544883</td>\n",
       "      <td>0.423655</td>\n",
       "      <td>0.645894</td>\n",
       "      <td>0.437587</td>\n",
       "      <td>0.891773</td>\n",
       "      <td>0.963663</td>\n",
       "      <td>0.383442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.311796</td>\n",
       "      <td>0.696343</td>\n",
       "      <td>0.377752</td>\n",
       "      <td>0.179604</td>\n",
       "      <td>0.024679</td>\n",
       "      <td>0.067250</td>\n",
       "      <td>0.679393</td>\n",
       "      <td>0.453697</td>\n",
       "      <td>0.536579</td>\n",
       "      <td>0.896671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.401260</td>\n",
       "      <td>0.929291</td>\n",
       "      <td>0.099615</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>0.869489</td>\n",
       "      <td>0.454162</td>\n",
       "      <td>0.326701</td>\n",
       "      <td>0.232744</td>\n",
       "      <td>0.614465</td>\n",
       "      <td>0.033075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.174658</td>\n",
       "      <td>0.327988</td>\n",
       "      <td>0.680349</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.607249</td>\n",
       "      <td>0.477647</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.238413</td>\n",
       "      <td>0.514513</td>\n",
       "      <td>0.367928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.639705</td>\n",
       "      <td>0.408303</td>\n",
       "      <td>0.377407</td>\n",
       "      <td>0.809365</td>\n",
       "      <td>0.709035</td>\n",
       "      <td>0.954334</td>\n",
       "      <td>0.351936</td>\n",
       "      <td>0.897543</td>\n",
       "      <td>0.769967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953235</th>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.313539</td>\n",
       "      <td>0.058766</td>\n",
       "      <td>0.499187</td>\n",
       "      <td>0.808221</td>\n",
       "      <td>0.138732</td>\n",
       "      <td>0.301711</td>\n",
       "      <td>0.577402</td>\n",
       "      <td>0.157363</td>\n",
       "      <td>0.523020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953236</th>\n",
       "      <td>0.543741</td>\n",
       "      <td>0.951535</td>\n",
       "      <td>0.600908</td>\n",
       "      <td>0.910568</td>\n",
       "      <td>0.998656</td>\n",
       "      <td>0.098114</td>\n",
       "      <td>0.383854</td>\n",
       "      <td>0.286133</td>\n",
       "      <td>0.111796</td>\n",
       "      <td>0.869804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953237</th>\n",
       "      <td>0.638730</td>\n",
       "      <td>0.528217</td>\n",
       "      <td>0.284441</td>\n",
       "      <td>0.994471</td>\n",
       "      <td>0.296285</td>\n",
       "      <td>0.881466</td>\n",
       "      <td>0.497050</td>\n",
       "      <td>0.738617</td>\n",
       "      <td>0.565598</td>\n",
       "      <td>0.956137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953238</th>\n",
       "      <td>0.087231</td>\n",
       "      <td>0.090555</td>\n",
       "      <td>0.344656</td>\n",
       "      <td>0.593301</td>\n",
       "      <td>0.958200</td>\n",
       "      <td>0.172662</td>\n",
       "      <td>0.580123</td>\n",
       "      <td>0.358753</td>\n",
       "      <td>0.348730</td>\n",
       "      <td>0.880162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953239</th>\n",
       "      <td>0.020439</td>\n",
       "      <td>0.880435</td>\n",
       "      <td>0.681310</td>\n",
       "      <td>0.059247</td>\n",
       "      <td>0.638324</td>\n",
       "      <td>0.281876</td>\n",
       "      <td>0.797858</td>\n",
       "      <td>0.524217</td>\n",
       "      <td>0.222334</td>\n",
       "      <td>0.115316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2953240 rows × 268 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "0        0.548814  0.715189  0.602763  0.544883  0.423655  0.645894  0.437587   \n",
       "1        0.311796  0.696343  0.377752  0.179604  0.024679  0.067250  0.679393   \n",
       "2        0.401260  0.929291  0.099615  0.945302  0.869489  0.454162  0.326701   \n",
       "3        0.174658  0.327988  0.680349  0.063208  0.607249  0.477647  0.284000   \n",
       "4        0.039993  0.639705  0.408303  0.377407  0.809365  0.709035  0.954334   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "2953235  0.002580  0.313539  0.058766  0.499187  0.808221  0.138732  0.301711   \n",
       "2953236  0.543741  0.951535  0.600908  0.910568  0.998656  0.098114  0.383854   \n",
       "2953237  0.638730  0.528217  0.284441  0.994471  0.296285  0.881466  0.497050   \n",
       "2953238  0.087231  0.090555  0.344656  0.593301  0.958200  0.172662  0.580123   \n",
       "2953239  0.020439  0.880435  0.681310  0.059247  0.638324  0.281876  0.797858   \n",
       "\n",
       "                7         8         9  ...  x0_Skin_18M  x0_Skin_24M  \\\n",
       "0        0.891773  0.963663  0.383442  ...          0.0          0.0   \n",
       "1        0.453697  0.536579  0.896671  ...          0.0          0.0   \n",
       "2        0.232744  0.614465  0.033075  ...          0.0          0.0   \n",
       "3        0.238413  0.514513  0.367928  ...          0.0          0.0   \n",
       "4        0.351936  0.897543  0.769967  ...          0.0          0.0   \n",
       "...           ...       ...       ...  ...          ...          ...   \n",
       "2953235  0.577402  0.157363  0.523020  ...          0.0          0.0   \n",
       "2953236  0.286133  0.111796  0.869804  ...          0.0          0.0   \n",
       "2953237  0.738617  0.565598  0.956137  ...          0.0          0.0   \n",
       "2953238  0.358753  0.348730  0.880162  ...          0.0          0.0   \n",
       "2953239  0.524217  0.222334  0.115316  ...          0.0          0.0   \n",
       "\n",
       "         x0_Stomach_09M  x0_Stomach_12M  x0_Stomach_18M  x0_Stomach_24M  \\\n",
       "0                   0.0             0.0             0.0             0.0   \n",
       "1                   0.0             0.0             0.0             0.0   \n",
       "2                   0.0             0.0             0.0             0.0   \n",
       "3                   0.0             0.0             0.0             0.0   \n",
       "4                   0.0             0.0             0.0             0.0   \n",
       "...                 ...             ...             ...             ...   \n",
       "2953235             0.0             0.0             0.0             0.0   \n",
       "2953236             0.0             0.0             0.0             0.0   \n",
       "2953237             0.0             0.0             0.0             0.0   \n",
       "2953238             0.0             0.0             0.0             0.0   \n",
       "2953239             0.0             0.0             0.0             0.0   \n",
       "\n",
       "         x0_WAT_09M  x0_WAT_12M  x0_WAT_18M  x0_WAT_24M  \n",
       "0               0.0         0.0         0.0         0.0  \n",
       "1               0.0         0.0         0.0         0.0  \n",
       "2               0.0         0.0         0.0         0.0  \n",
       "3               0.0         0.0         0.0         0.0  \n",
       "4               0.0         0.0         0.0         0.0  \n",
       "...             ...         ...         ...         ...  \n",
       "2953235         0.0         0.0         0.0         1.0  \n",
       "2953236         0.0         0.0         0.0         1.0  \n",
       "2953237         0.0         0.0         0.0         1.0  \n",
       "2953238         0.0         0.0         0.0         1.0  \n",
       "2953239         0.0         0.0         0.0         1.0  \n",
       "\n",
       "[2953240 rows x 268 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(tensor_height, tensor_width, tensor_channels)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # or more neurons in the last layer depending on your specific task\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')  # Define optimizer and loss function\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff63747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69080dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78ac1289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Hypermatrix Factor 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bin 1</th>\n",
       "      <td>0.148185</td>\n",
       "      <td>0.202317</td>\n",
       "      <td>0.552431</td>\n",
       "      <td>0.352808</td>\n",
       "      <td>0.262560</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 2</th>\n",
       "      <td>0.440417</td>\n",
       "      <td>0.677599</td>\n",
       "      <td>0.836292</td>\n",
       "      <td>0.766274</td>\n",
       "      <td>0.589942</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 3</th>\n",
       "      <td>0.213192</td>\n",
       "      <td>0.669842</td>\n",
       "      <td>0.555024</td>\n",
       "      <td>0.287198</td>\n",
       "      <td>0.257054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 4</th>\n",
       "      <td>0.056439</td>\n",
       "      <td>0.028592</td>\n",
       "      <td>0.673903</td>\n",
       "      <td>0.097296</td>\n",
       "      <td>0.053679</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 5</th>\n",
       "      <td>0.523527</td>\n",
       "      <td>0.761064</td>\n",
       "      <td>0.398477</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.162360</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 6</th>\n",
       "      <td>0.257404</td>\n",
       "      <td>0.035385</td>\n",
       "      <td>0.594281</td>\n",
       "      <td>0.891553</td>\n",
       "      <td>0.126924</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 7</th>\n",
       "      <td>0.950649</td>\n",
       "      <td>0.791795</td>\n",
       "      <td>0.326750</td>\n",
       "      <td>0.353456</td>\n",
       "      <td>0.271203</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 8</th>\n",
       "      <td>0.509387</td>\n",
       "      <td>0.171507</td>\n",
       "      <td>0.322688</td>\n",
       "      <td>0.401170</td>\n",
       "      <td>0.405266</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 9</th>\n",
       "      <td>0.655325</td>\n",
       "      <td>0.280910</td>\n",
       "      <td>0.221015</td>\n",
       "      <td>0.222105</td>\n",
       "      <td>0.875663</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 10</th>\n",
       "      <td>0.093985</td>\n",
       "      <td>0.665979</td>\n",
       "      <td>0.378905</td>\n",
       "      <td>0.310335</td>\n",
       "      <td>0.833544</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 11</th>\n",
       "      <td>0.534310</td>\n",
       "      <td>0.313174</td>\n",
       "      <td>0.795038</td>\n",
       "      <td>0.718072</td>\n",
       "      <td>0.145150</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 12</th>\n",
       "      <td>0.086070</td>\n",
       "      <td>0.179945</td>\n",
       "      <td>0.460263</td>\n",
       "      <td>0.783534</td>\n",
       "      <td>0.443371</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 13</th>\n",
       "      <td>0.472043</td>\n",
       "      <td>0.881779</td>\n",
       "      <td>0.479290</td>\n",
       "      <td>0.342993</td>\n",
       "      <td>0.749916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 14</th>\n",
       "      <td>0.552564</td>\n",
       "      <td>0.684560</td>\n",
       "      <td>0.327362</td>\n",
       "      <td>0.727035</td>\n",
       "      <td>0.386615</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bin 15</th>\n",
       "      <td>0.300624</td>\n",
       "      <td>0.223397</td>\n",
       "      <td>0.265675</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.420434</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature 1  Feature 2  Feature 3  Feature 4  Feature 5  \\\n",
       "Bin 1    0.148185   0.202317   0.552431   0.352808   0.262560   \n",
       "Bin 2    0.440417   0.677599   0.836292   0.766274   0.589942   \n",
       "Bin 3    0.213192   0.669842   0.555024   0.287198   0.257054   \n",
       "Bin 4    0.056439   0.028592   0.673903   0.097296   0.053679   \n",
       "Bin 5    0.523527   0.761064   0.398477   0.001722   0.162360   \n",
       "Bin 6    0.257404   0.035385   0.594281   0.891553   0.126924   \n",
       "Bin 7    0.950649   0.791795   0.326750   0.353456   0.271203   \n",
       "Bin 8    0.509387   0.171507   0.322688   0.401170   0.405266   \n",
       "Bin 9    0.655325   0.280910   0.221015   0.222105   0.875663   \n",
       "Bin 10   0.093985   0.665979   0.378905   0.310335   0.833544   \n",
       "Bin 11   0.534310   0.313174   0.795038   0.718072   0.145150   \n",
       "Bin 12   0.086070   0.179945   0.460263   0.783534   0.443371   \n",
       "Bin 13   0.472043   0.881779   0.479290   0.342993   0.749916   \n",
       "Bin 14   0.552564   0.684560   0.327362   0.727035   0.386615   \n",
       "Bin 15   0.300624   0.223397   0.265675   0.030700   0.420434   \n",
       "\n",
       "        Hypermatrix Factor 4  \n",
       "Bin 1                      8  \n",
       "Bin 2                      5  \n",
       "Bin 3                      1  \n",
       "Bin 4                     10  \n",
       "Bin 5                      5  \n",
       "Bin 6                      5  \n",
       "Bin 7                      2  \n",
       "Bin 8                      8  \n",
       "Bin 9                      4  \n",
       "Bin 10                     8  \n",
       "Bin 11                     8  \n",
       "Bin 12                     7  \n",
       "Bin 13                     1  \n",
       "Bin 14                     1  \n",
       "Bin 15                     9  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to create a dataframe with specified number of emails and features, filled with random numbers\n",
    "def create_dataframe(num_emails, num_features):\n",
    "    column_labels = [f'Feature {i+1}' for i in range(num_features)]\n",
    "    row_labels = [f'Bin {i+1}' for i in range(num_emails)]\n",
    "    data = np.random.rand(num_emails, num_features)\n",
    "    return pd.DataFrame(data, index=row_labels, columns=column_labels)\n",
    "\n",
    "# Example usage of the function\n",
    "num_emails = 15  # Number of emails\n",
    "num_features = 5  # Number of features\n",
    "dataframe = create_dataframe(num_emails, num_features)\n",
    "\n",
    "\n",
    "values = np.random.randint(1, 11, size=num_emails)\n",
    "# Adding a new column named 'Prediction' with random choices between 'Real' and 'Spam'\n",
    "dataframe['Hypermatrix Factor 4'] = values\n",
    "\n",
    "dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cae18ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Feature 1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature 5</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Ranking\n",
       "Feature 1        1\n",
       "Feature 2        2\n",
       "Feature 3        3\n",
       "Feature 4        2\n",
       "Feature 5        3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new DataFrame with features as rows and a single column for rankings\n",
    "num_features = 5  # Number of features\n",
    "feature_labels = [f'Feature {i+1}' for i in range(num_features)]\n",
    "rankings = [1, 2, 3, 2, 3]\n",
    "\n",
    "# Creating the DataFrame\n",
    "feature_rankings_df = pd.DataFrame(rankings, index=feature_labels, columns=['Ranking'])\n",
    "\n",
    "feature_rankings_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e65bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scRNAseq",
   "language": "python",
   "name": "scrnaseq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
