{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ee5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bam_directory='/home/dwk681/workspace/cluster_cells_from_GSE189158_NOMe_HiC/filesFromCluster/bam'\n",
      "methy_directory='/home/dwk681/workspace/cluster_cells_from_GSE189158_NOMe_HiC/filesFromCluster/bam/methylation/filter_low_qual'\n",
      "software_directory='../../bin/softwarefiles'\n",
      "chrom_file='../../bin/softwarefiles/hg19.autosome.chrom.sizes'\n",
      "fragments_file='../../bin/softwarefiles/hg19_DpnII.txt'\n",
      "output_directory='../../projects/single_cell_files'\n",
      "hg19_fa_url='ftp://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz'\n",
      "filtered_list='../../projects/single_cell_files/filtered_bam_list.txt'\n",
      "schicluster_env='schicluster2'\n",
      "bisulfite_env='bisulfitehic27'\n",
      "min_high_quality_reads='250000'\n",
      "resolutions=1000000:1Mb\n",
      "impute=True\n",
      "cluster_compartments=True\n",
      "cumulant=True\n",
      "Processing /home/dwk681/workspace/cluster_cells_from_GSE189158_NOMe_HiC/filesFromCluster/bam/methylation/filter_low_qual/sc24.ACTTGA.methy.b37.bw\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cumulant_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 160\u001b[0m\n\u001b[1;32m    158\u001b[0m     large_bin_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(res_value)\n\u001b[1;32m    159\u001b[0m     small_bin_size \u001b[38;5;241m=\u001b[39m large_bin_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m--> 160\u001b[0m     \u001b[43mprocess_bigwig_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbigwigfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlarge_bin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msmall_bin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mres_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid resolution format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresolution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 138\u001b[0m, in \u001b[0;36mprocess_bigwig_file\u001b[0;34m(bigwigfile, large_bin_size, small_bin_size, resolution_label, base_directory, prefix)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cumulant_tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# Save the cumulant matrix as a .h5 file\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(new_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m hf:\n\u001b[0;32m--> 138\u001b[0m         hf\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethy_cumulant\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[43mcumulant_matrix\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cumulant_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyBigWig\n",
    "import numpy as np\n",
    "from scipy.stats import ks_2samp\n",
    "import h5py\n",
    "\n",
    "# Import variables from config_and_print.py\n",
    "from config_and_print import methy_directory, output_directory, resolutions, filtered_list\n",
    "\n",
    "# Read the filtered bam list\n",
    "with open(filtered_list, 'r') as f:\n",
    "    filtered_prefixes = set(line.strip() for line in f)\n",
    "\n",
    "# Define the function to compute the third-order cumulant\n",
    "def compute_third_order_cumulant(matrix):\n",
    "    try:\n",
    "        n, m = matrix.shape\n",
    "        mean_vec = np.mean(matrix, axis=1, keepdims=True)\n",
    "        centered_matrix = matrix - mean_vec\n",
    "        m_ijk = np.zeros((n, n, n))\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                for k in range(n):\n",
    "                    m_ijk[i, j, k] = np.mean(centered_matrix[i] * centered_matrix[j] * centered_matrix[k])\n",
    "        \n",
    "        m_ij = np.dot(centered_matrix, centered_matrix.T) / m\n",
    "        m_i = np.mean(centered_matrix, axis=1)\n",
    "\n",
    "        kappa_ijk = np.zeros((n, n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                for k in range(n):\n",
    "                    kappa_ijk[i, j, k] = (\n",
    "                        m_ijk[i, j, k]\n",
    "                        - (m_i[i] * m_ij[j, k] + m_i[j] * m_ij[i, k] + m_i[k] * m_ij[i, j])\n",
    "                        + 2 * m_i[i] * m_i[j] * m_i[k]\n",
    "                    )\n",
    "\n",
    "        # Normalize by dividing by the standard deviations\n",
    "        std_vec = np.std(matrix, axis=1, keepdims=True)\n",
    "        normalized_kappa_ijk = np.zeros((n, n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                for k in range(n):\n",
    "                    denominator = std_vec[i] * std_vec[j] * std_vec[k]\n",
    "                    normalized_kappa_ijk[i, j, k] = kappa_ijk[i, j, k] / denominator if denominator != 0 else np.nan\n",
    "\n",
    "        min_value = np.min(np.nan_to_num(normalized_kappa_ijk))\n",
    "        if min_value < 0:\n",
    "            normalized_kappa_ijk -= min_value\n",
    "\n",
    "        return normalized_kappa_ijk\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to compute third-order cumulant: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process each bigWig file\n",
    "def process_bigwig_file(bigwigfile, large_bin_size, small_bin_size, resolution_label, base_directory, prefix):\n",
    "    bw = pyBigWig.open(bigwigfile)\n",
    "    chromosomes = bw.chroms()\n",
    "\n",
    "    for chrom in chromosomes:\n",
    "        # Ensure chrom_string is always in the format 'chrN'\n",
    "        if isinstance(chrom, int) or chrom.isdigit():\n",
    "            chrom_string = f'chr{chrom}'\n",
    "        else:\n",
    "            chrom_string = chrom if chrom.startswith('chr') else f'chr{chrom}'\n",
    "\n",
    "        if chrom_string in [f'chr{i}' for i in range(1, 23)]:\n",
    "            # Create chromosome-specific directory if it doesn't exist\n",
    "            chrom_directory = os.path.join(base_directory, chrom_string)\n",
    "            os.makedirs(chrom_directory, exist_ok=True)\n",
    "\n",
    "            # Define the filename for the matrix\n",
    "            new_filename = os.path.join(chrom_directory, f'{prefix}_{chrom_string}.h5')\n",
    "\n",
    "            # Check if the file already exists\n",
    "            if os.path.exists(new_filename):\n",
    "                print(f\"File {new_filename} already exists, skipping computation.\")\n",
    "                continue\n",
    "\n",
    "            chrom_length = chromosomes[chrom]\n",
    "            large_bins = range(0, chrom_length, large_bin_size)\n",
    "            num_large_bins = len(large_bins)\n",
    "\n",
    "            integrals = np.zeros((large_bin_size // small_bin_size, num_large_bins))\n",
    "\n",
    "            for i, large_bin_start in enumerate(large_bins):\n",
    "                for j in range(large_bin_size // small_bin_size):\n",
    "                    small_bin_start = large_bin_start + j * small_bin_size\n",
    "                    small_bin_end = small_bin_start + small_bin_size\n",
    "\n",
    "                    # Ensure that the coordinates are within the chromosome boundaries\n",
    "                    if small_bin_start < 0:\n",
    "                        small_bin_start = 0\n",
    "                    if small_bin_end > chrom_length:\n",
    "                        small_bin_end = chrom_length\n",
    "\n",
    "                    # Check if the adjusted small_bin_start is still greater than or equal to small_bin_end\n",
    "                    if small_bin_start >= small_bin_end:\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        # Get data within the small bin\n",
    "                        small_bin_data = bw.values(chrom, int(small_bin_start), int(small_bin_end))\n",
    "\n",
    "                        # Calculate the integral of data in the small bin\n",
    "                        integral = np.trapz(small_bin_data)\n",
    "\n",
    "                        # Store the integral in the corresponding list\n",
    "                        integrals[j, i] = integral\n",
    "                    except Exception as e:\n",
    "                        # Print the exception and relevant information\n",
    "                        print(f\"An error occurred for chromosome {chrom}, large bin {i}, small bin {j}: {e}\")\n",
    "\n",
    "            # create your matrices\n",
    "            num_rows, num_columns = integrals.shape\n",
    "            p_value_ks_matrix = np.zeros((num_columns, num_columns))\n",
    "            epsilon = 1e-10  # Define your epsilon value here\n",
    "\n",
    "            for i in range(num_columns):\n",
    "                for j in range(i, num_columns):\n",
    "                    if i == j:\n",
    "                        p_value_ks_matrix[i, j] = 1.0\n",
    "                    else:\n",
    "                        _, ks_p_value = ks_2samp(integrals[:, i], integrals[:, j])\n",
    "\n",
    "                        p_value_ks_matrix[i, j] = ks_p_value\n",
    "                        p_value_ks_matrix[j, i] = ks_p_value\n",
    "                        \n",
    "                        #p_value_ks_matrix[i, j] = np.log10(ks_p_value + epsilon)\n",
    "                        #p_value_ks_matrix[j, i] = np.log10(ks_p_value + epsilon)\n",
    "\n",
    "            # Compute the third-order cumulant\n",
    "            cumulant_tensor = compute_third_order_cumulant(p_value_ks_matrix) + 1\n",
    "\n",
    "            if cumulant_tensor is not None:\n",
    "                # Save the cumulant matrix as a .h5 file\n",
    "                with h5py.File(new_filename, 'w') as hf:\n",
    "                    hf.create_dataset('methy_cumulant', data=cumulant_tensor)\n",
    "\n",
    "# Ensure resolutions is processed as a list of strings\n",
    "resolutions_list = [res.strip() for res in resolutions.split(',')]\n",
    "\n",
    "# Iterate through the files in methy_directory\n",
    "for root, dirs, files in os.walk(methy_directory):\n",
    "    for file in files:\n",
    "        if file.endswith('.methy.b37.bw'):\n",
    "            # Extract the prefix for filtering\n",
    "            prefix = '.'.join(file.split('.')[:2])\n",
    "            if prefix in filtered_prefixes:\n",
    "                bigwigfile = os.path.join(root, file)\n",
    "                print(f\"Processing {bigwigfile}\")\n",
    "                for resolution in resolutions_list:\n",
    "                    try:\n",
    "                        res_value, res_label = resolution.split(\":\")\n",
    "                        # Create the base directory for the matrices\n",
    "                        base_directory = os.path.join(output_directory, f'methy_{res_label}_cumulant_dir')\n",
    "                        os.makedirs(base_directory, exist_ok=True)\n",
    "                        large_bin_size = int(res_value)\n",
    "                        small_bin_size = large_bin_size // 100\n",
    "                        process_bigwig_file(bigwigfile, large_bin_size, small_bin_size, res_label, base_directory, prefix)\n",
    "                    except ValueError:\n",
    "                        print(f\"Invalid resolution format: {resolution}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a351789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiomics6",
   "language": "python",
   "name": "multiomics6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
